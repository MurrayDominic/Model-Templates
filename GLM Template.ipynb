{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a502c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    r2_score,\n",
    "    accuracy_score, \n",
    "    recall_score, \n",
    "    precision_score, \n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, \n",
    "    PoissonRegressor, \n",
    "    GammaRegressor, \n",
    "    TweedieRegressor, \n",
    "    LogisticRegression)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b36918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_0  feature_1  feature_2  feature_3  feature_4  target_gaussian  \\\n",
      "0   0.496714  -0.138264   0.647689   1.523030  -0.234153         6.719300   \n",
      "1  -0.234137   1.579213   0.767435  -0.469474   0.542560        -4.108712   \n",
      "2  -0.463418  -0.465730   0.241962  -1.913280  -1.724918        -3.988917   \n",
      "3  -0.562288  -1.012831   0.314247  -0.908024  -1.412304        -0.584651   \n",
      "4   1.465649  -0.225776   0.067528  -1.424748  -0.544383        -2.131223   \n",
      "\n",
      "   target_poisson  target_gamma  \n",
      "0               7     14.142504  \n",
      "1               0      0.116827  \n",
      "2               0      0.881585  \n",
      "3               0      2.776460  \n",
      "4               1      0.892098  \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic dataset\n",
    "n_samples = 500\n",
    "n_features = 5\n",
    "\n",
    "# Features\n",
    "X = np.random.normal(0, 1, size=(n_samples, n_features))\n",
    "\n",
    "# Coefficients\n",
    "coef = np.array([1.5, -2.0, 0.5, 3.0, -1.0])\n",
    "\n",
    "# Linear combination + noise\n",
    "linear_part = X @ coef\n",
    "\n",
    "# Target variable: Gaussian (for LinearRegression)\n",
    "y_gaussian = linear_part + np.random.normal(0, 1, n_samples)\n",
    "\n",
    "# Target variable: Poisson (counts, for PoissonRegressor)\n",
    "y_poisson = np.random.poisson(np.exp(linear_part / 3))  # scale to avoid huge counts\n",
    "\n",
    "# Target variable: Gamma (positive continuous)\n",
    "y_gamma = np.random.gamma(shape=2.0, scale=np.exp(linear_part / 5))\n",
    "\n",
    "# Create DataFrame\n",
    "df_regression = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(n_features)])\n",
    "df_regression[\"target_gaussian\"] = y_gaussian\n",
    "df_regression[\"target_poisson\"] = y_poisson\n",
    "df_regression[\"target_gamma\"] = y_gamma\n",
    "\n",
    "print(df_regression.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"your_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add tests for he distribuiton - this can the feed into the model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4497af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df_regression.copy().drop(['target_poisson', 'target_gamma'], axis =1)\n",
    "\n",
    "X = df.drop(\"target_gaussian\", axis=1)\n",
    "y = df[\"target_gaussian\"]\n",
    "\n",
    "is_classification = y.nunique() <= 10 and y.dtype != float\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839c0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_classification:\n",
    "    models = {\n",
    "        \"Logistic Regression (GLM)\": {\n",
    "            \"model\": LogisticRegression(max_iter=1000),\n",
    "            \"params\": {\n",
    "                \"model__C\": [0.01, 0.1, 1, 10]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    models = {\n",
    "        \"Linear Regression (Gaussian GLM)\": {\"model\": LinearRegression(), \"params\": {}},\n",
    "        \"Poisson GLM\": {\n",
    "            \"model\": PoissonRegressor(max_iter=500),\n",
    "            \"params\": {\"model__alpha\": [0.01, 0.1, 1.0]}\n",
    "        },\n",
    "        \"Gamma GLM\": {\n",
    "            \"model\": GammaRegressor(max_iter=500),\n",
    "            \"params\": {\"model__alpha\": [0.01, 0.1, 1.0]}\n",
    "        },\n",
    "        \"Tweedie GLM (compound Poisson)\": {\n",
    "            \"model\": TweedieRegressor(power=1.5, max_iter=500),\n",
    "            \"params\": {\"model__alpha\": [0.01, 0.1, 1.0]}\n",
    "        },\n",
    "    }\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a446bd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running → Linear Regression (Gaussian GLM)\n",
      "\n",
      "Running → Poisson GLM\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py\", line 225, in fit\n    raise ValueError(\nValueError: Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      4\u001b[39m pipe = Pipeline([\n\u001b[32m      5\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m\"\u001b[39m, StandardScaler()),\n\u001b[32m      6\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      7\u001b[39m ])\n\u001b[32m      9\u001b[39m tuning = GridSearchCV(\n\u001b[32m     10\u001b[39m     pipe, cfg[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m], cv=\u001b[32m5\u001b[39m,\n\u001b[32m     11\u001b[39m     scoring=\u001b[33m\"\u001b[39m\u001b[33mneg_mean_squared_error\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_classification \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m, refit=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtuning\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m y_pred = tuning.predict(X_test)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# METRICS — CLASSIFICATION\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1028\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1026\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Dominic\\Documents\\Quant\\Model Templates\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py\", line 225, in fit\n    raise ValueError(\nValueError: Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n"
     ]
    }
   ],
   "source": [
    "for name, cfg in models.items():\n",
    "    print(f\"\\nRunning → {name}\")\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", cfg[\"model\"])\n",
    "    ])\n",
    "\n",
    "    tuning = GridSearchCV(\n",
    "        pipe, cfg[\"params\"], cv=5,\n",
    "        scoring=\"neg_mean_squared_error\" if not is_classification else \"accuracy\",\n",
    "        n_jobs=-1, refit=True\n",
    "    )\n",
    "    tuning.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = tuning.predict(X_test)\n",
    "\n",
    "    # METRICS — CLASSIFICATION\n",
    "    if is_classification:\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Best Params\": tuning.best_params_,\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"Recall\": recall_score(y_test, y_pred),\n",
    "            \"Precision\": precision_score(y_test, y_pred),\n",
    "            \"F1 Score\": f1_score(y_test, y_pred),\n",
    "        })\n",
    "\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        continue\n",
    "\n",
    "\n",
    "    # METRICS — REGRESSION (AIC + BIC INCLUDED)\n",
    "    # Residual sum of squares\n",
    "    RSS = np.sum((y_test - y_pred) ** 2)\n",
    "    n = len(y_test)\n",
    "    k = X_train.shape[1]  # number of parameters\n",
    "\n",
    "    AIC = n * np.log(RSS / n) + 2 * k\n",
    "    BIC = n * np.log(RSS / n) + k * np.log(n)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best Params\": tuning.best_params_,\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"R² Score\": r2_score(y_test, y_pred),\n",
    "        \"AIC\": AIC,\n",
    "        \"BIC\": BIC\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93292de",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n===== MODEL PERFORMANCE SUMMARY =====\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067594d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_classification:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "else:\n",
    "    results_df.plot(x=\"Model\", y=\"AIC\", kind=\"bar\", title=\"AIC Comparison\")\n",
    "    plt.show()\n",
    "\n",
    "    results_df.plot(x=\"Model\", y=\"BIC\", kind=\"bar\", title=\"BIC Comparison\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
